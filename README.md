# Indian E-Consultation Analysis Platform

AI-powered sentiment analysis and emotion detection platform for Indian e-consultation feedback with multilingual support (Hindi, English, Code-mixed).

## ğŸŒŸ Features

- **Multi-language Support**: Hindi, English, and code-mixed text analysis
- **Comprehensive Analysis**: Sentiment analysis, emotion detection, and text summarization
- **Interactive Dashboards**: Modern React frontend with advanced data visualizations
- **Word Cloud Analytics**: Interactive word filtering and comment exploration
- **Real-time Processing**: Batch processing with progress tracking
- **Export Capabilities**: Download results in CSV format
- **Dark Mode Support**: Professional UI with light/dark themes

## ğŸš€ Live Demo

- **Frontend**: https://your-project.vercel.app
- **API Documentation**: https://your-service.onrender.com/docs

## ğŸ—ï¸ Architecture

### Frontend (InsightGov Platform)
- **Framework**: Next.js 14 with TypeScript
- **Styling**: Tailwind CSS v4 with Shadcn/ui components
- **State Management**: React hooks
- **Visualizations**: Custom SVG charts and interactive components

### Backend (FastAPI)
- **Framework**: FastAPI with Python 3.10+
- **ML Models**: 
  - DistilBERT for sentiment analysis
  - XLM-RoBERTa for multilingual support
  - Emotion classification models
  - TF-IDF and extractive summarization
- **Processing**: Batch processing with async operations

## ğŸ“Š Analysis Capabilities

1. **Sentiment Analysis**: Positive, Negative, Neutral classification
2. **Emotion Detection**: Joy, Sadness, Anger, Fear, Surprise, Disgust, Neutral
3. **Language Detection**: Automatic identification of Hindi, English, Code-mixed
4. **Text Summarization**: Extractive and abstractive summarization
5. **Confidence Scoring**: ML model confidence for all predictions

## ğŸ› ï¸ Local Development

### Prerequisites
- Python 3.10+
- Node.js 18+
- Git

### Backend Setup
```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/indian-econsultation-analysis.git
cd indian-econsultation-analysis

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Start API server
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
```

### Frontend Setup
```bash
# Navigate to frontend directory
cd insightgov-platform

# Install dependencies
npm install

# Start development server
npm run dev
```

Access the application at `http://localhost:3000`

## ğŸ“ Project Structure

```
â”œâ”€â”€ api/                    # FastAPI backend
â”‚   â”œâ”€â”€ main.py            # Main API application
â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”œâ”€â”€ insightgov-platform/     # Next.js frontend
â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”œâ”€â”€ app/              # Next.js 14 app directory
â”‚   â””â”€â”€ lib/              # Utility functions
â”œâ”€â”€ src/                   # Core ML modules
â”‚   â”œâ”€â”€ inference/        # ML inference pipeline
â”‚   â”œâ”€â”€ models/           # Model configurations
â”‚   â””â”€â”€ training/         # Training scripts
â”œâ”€â”€ scripts/              # Utility scripts
â””â”€â”€ docs/                 # Documentation
```

## ğŸŒ Deployment

### Production Deployment
1. **Backend**: Deploy on Render.com or similar platform
2. **Frontend**: Deploy on Vercel with environment variables
3. **Environment Variables**: 
   - `NEXT_PUBLIC_API_BASE`: Backend API URL

### Docker Deployment
```bash
# Backend
docker build -f Dockerfile.backend -t econsult-api .
docker run -p 8000:8000 econsult-api

# Frontend
docker build -f Dockerfile.frontend -t econsult-frontend .
docker run -p 3000:3000 econsult-frontend
```

## ğŸ”§ Configuration

### Environment Variables
- `NEXT_PUBLIC_API_BASE`: Backend API base URL
- `LOG_LEVEL`: Logging level (info, debug, error)
- `MODEL_CACHE_DIR`: Directory for caching ML models

## ğŸ“ˆ Performance

- **Processing Speed**: ~10-50 comments per batch
- **Model Loading**: First request may take 2-3 minutes (model download)
- **Memory Requirements**: 1-2GB RAM for ML models
- **Supported File Formats**: CSV, JSON, TXT

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Hugging Face for transformer models
- Next.js and React community
- FastAPI framework
- Tailwind CSS and Shadcn/ui components

## ğŸ“ Support

For support, please open an issue on GitHub or contact [your-email@example.com]

---

Built with â¤ï¸ for improving healthcare feedback analysis in India

A comprehensive modular Python project for analyzing sentiment and generating summaries from Indian e-consultation comments, with support for Hindi, English, and code-mixed content.

## Features

- **Multi-language Support**: Process Hindi, English, and code-mixed comments
- **Sentiment Analysis**: Using IndicBERT/mBERT for accurate sentiment classification
- **Text Summarization**: Both extractive (TextRank) and abstractive (T5/BART) approaches
- **Emotion Detection**: Secondary classification for detailed emotion analysis
- **Interactive Visualization**: Dashboards with filtering and word clouds
- **API Deployment**: FastAPI backend with Docker containerization
- **Database Integration**: PostgreSQL/MongoDB support for data persistence

## Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py          # Data loading utilities
â”‚   â”‚   â””â”€â”€ preprocessor.py    # Text preprocessing and cleaning
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sentiment.py       # Sentiment analysis models
â”‚   â”‚   â”œâ”€â”€ summarization.py   # Summarization models
â”‚   â”‚   â””â”€â”€ emotion.py         # Emotion detection models
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py         # Model training utilities
â”‚   â”‚   â””â”€â”€ evaluator.py       # Model evaluation metrics
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ predictor.py       # Inference pipeline
â”‚   â””â”€â”€ visualization/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ dashboard.py       # Interactive dashboard
â”‚       â””â”€â”€ charts.py          # Visualization utilities
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py               # FastAPI application
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sentiment.py      # Sentiment analysis endpoints
â”‚   â”‚   â””â”€â”€ summarization.py  # Summarization endpoints
â”‚   â””â”€â”€ schemas.py            # Pydantic models
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_sentiment.py    # Training script for sentiment analysis
â”‚   â”œâ”€â”€ train_summarization.py # Training script for summarization
â”‚   â”œâ”€â”€ evaluate_models.py    # Model evaluation script
â”‚   â””â”€â”€ serve_api.py          # API server script
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Raw data files
â”‚   â”œâ”€â”€ processed/            # Processed data
â”‚   â””â”€â”€ sample/               # Sample datasets
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ sentiment/            # Trained sentiment models
â”‚   â”œâ”€â”€ summarization/        # Trained summarization models
â”‚   â””â”€â”€ emotion/              # Trained emotion models
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ config.yaml
```

## Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd indian-econsultation-analysis
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Download required models:
```bash
python scripts/download_models.py
```

## Quick Start

### 1. Data Preparation
```python
from src.data.loader import DataLoader
from src.data.preprocessor import TextPreprocessor

# Load data
loader = DataLoader()
data = loader.load_csv("data/sample/comments.csv")

# Preprocess
preprocessor = TextPreprocessor()
processed_data = preprocessor.process(data)
```

### 2. Sentiment Analysis
```python
from src.models.sentiment import SentimentAnalyzer

analyzer = SentimentAnalyzer(model_name="ai4bharat/indic-bert")
results = analyzer.predict(processed_data)
```

### 3. Text Summarization
```python
from src.models.summarization import Summarizer

summarizer = Summarizer(method="textrank")
summaries = summarizer.generate_summary(processed_data)
```

### 4. Run API Server

**Choose the appropriate version based on your deployment environment:**

```bash
# ğŸª¶ Lightweight version (512MB RAM, deployment-optimized)
./start_lightweight_api.bat

# ğŸš€ Full ML version (1GB+ RAM, maximum accuracy)
./start_api.bat

# âš¡ Production version (auto-detects environment)
python api/production_main.py
```

**Memory Usage Comparison:**
- **Lightweight**: ~150MB (VADER, TextBlob, Custom Lexicons)
- **Full ML**: ~800-1200MB (DistilBERT, XLM-RoBERTa, Transformers)

**Deployment Options:**
- **Render 512MB Plan**: Use lightweight version (`MEMORY_LIMIT_MB=512`)
- **Render 1GB+ Plan**: Use full ML version for best accuracy

## Training Custom Models

### Sentiment Analysis
```bash
python scripts/train_sentiment.py --data_path data/processed/sentiment_data.csv --model_name indic-bert
```

### Summarization
```bash
python scripts/train_summarization.py --data_path data/processed/summary_data.csv --model_name t5-small
```

## API Usage

The FastAPI server provides REST endpoints for sentiment analysis and summarization:

- `POST /sentiment/analyze` - Analyze sentiment of comments
- `POST /summarization/generate` - Generate summaries
- `GET /health` - Health check endpoint

Example request:
```python
import requests

response = requests.post(
    "http://localhost:8000/sentiment/analyze",
    json={"comments": ["à¤¯à¤¹ à¤¬à¤¹à¥à¤¤ à¤…à¤šà¥à¤›à¥€ à¤¸à¥‡à¤µà¤¾ à¤¹à¥ˆ", "This service needs improvement"]}
)
```

## ğŸŒ Production Deployment

### Option 1: Render.com + Vercel (Recommended for 512MB)

**Backend (Render.com - Lightweight):**
1. Connect your GitHub repository to Render
2. Use `render.yaml` configuration (pre-configured for 512MB)
3. Set environment variables:
   - `ENVIRONMENT=production`
   - `MEMORY_LIMIT_MB=512`
4. Deploy with 512MB Starter plan ($7/month)

**Frontend (Vercel):**
1. Connect repository to Vercel
2. Set `API_BASE_URL` to your Render URL
3. Deploy automatically

### Option 2: Docker Deployment

```bash
# Build lightweight version
docker build -f docker/Dockerfile -t econsultation-analyzer .

# Run with docker-compose
docker-compose -f docker/docker-compose.yml up
```

### Memory Optimization Features

- **Automatic Model Selection**: Switches to lightweight models in production
- **Environment Detection**: Uses `MEMORY_LIMIT_MB` to choose appropriate models
- **512MB Compatibility**: Lightweight version fits comfortably in 512MB instances
- **Graceful Fallbacks**: Falls back to simpler models if heavy models fail to load

## Configuration

Edit `config.yaml` to customize:
- Model configurations
- Database settings
- API parameters
- Visualization options

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## License

MIT License - see LICENSE file for details.